Міністерство освіти і науки України
Харківський національний  університет радіоелектроніки


Кафедра програмної інженерії 



Лабораторна робота №5
 з дисципліни: «Архітектура програмного забезпечення»





Виконала
ст. гр. ПЗПІ-22-7
Рубаненко Марія Сергіївна
03 травня 2025 р.
Перевірив
ст. викл. Сокорчук І. П.








Харків 2025
1 ІСТОРІЯ ЗМІН

Таблиця 1.1 відображає зміни, внесені до документа.
Таблиця 1.1 - Історія змін
№	Дата	Версія звіту	Опис змін та виправлень
1	03.05.2025	0.1	Розділ «Історія змін» було додано до документа
2	03.05.2025	0.1	Розділ «Завдання до лабораторної роботи» було додано до документа
3	03.05.2025	0.1	Розділ «Опис виконаної роботи» було додано до документа
4	03.05.2025	0.1	Розділ «Висновки» було додано до документа
5	03.05.2025	0.1	У документ включено «Додаток А» з посиланням на відеоролик
6	03.05.2025	0.1	У документ включено «Додаток Б» 














2 ЗАВДАННЯ


Метою даної лабораторної роботи є ознайомлення з процесом локального та хмарного розгортання програмної системи, а також з її архітектурою, використаними технологіями та структурою компонентів. В рамках роботи необхідно проаналізувати функціональні можливості розробленої системи, зокрема систему для управління банками крові та координації донорських процесів, та здійснити її розгортання у локальному середовищі та на хмарній платформі.
Основні завдання лабораторної роботи:
	провести загальний аналіз архітектури програмної системи та визначити її ключові компоненти;
	описати використані технології, обґрунтувати їх вибір та сумісність між собою;
	побудувати UML-діаграму компонентів системи;
	реалізувати локальне розгортання системи та перевірити її працездатність у середовищі розробника;
	розписати алгоритм розгортання системи;
	побудувати архітектурну діаграму хмарного розгортання системи;
	узагальнити отримані результати та сформулювати висновки щодо переваг обраної архітектури та технологій.







3	ОПИС ВИКОНАНОЇ РОБОТИ


3.1  Загальний огляд програмної системи


Програмна система для управління банками крові та координації донорських процесів є комплексним цифровим рішенням, покликаним об’єднати ключових учасників сфери охорони здоров’я — банки крові, лікарні, транспортувальників та донорів — в одну цілісну, злагоджену екосистему. Основною метою є створення надійного технологічного середовища, яке забезпечує безперебійне постачання донорської крові до медичних установ, особливо у критичних ситуаціях, коли оперативність та точність є вирішальними.
Система охоплює весь цикл обігу крові — від моменту реєстрації донора до передачі оброблених компонентів у лікарню. У центрі роботи платформи лежить функціональність реального часу, що дозволяє учасникам оперативно реагувати на зміну потреб чи обставин. Так, лікарні мають змогу вчасно формувати заявки на поставку крові, бачити актуальні запаси в різних банках і швидко обирати оптимальні варіанти. У свою чергу, банки крові можуть ефективно управляти логістикою, контролювати процес обробки та зберігання компонентів крові, а також аналізувати динаміку використання завдяки вбудованій системі звітності.
Особливу увагу у розробці було приділено координації транспортування. Мобільний застосунок для транспортувальників дозволяє не лише бачити активні замовлення, а й фіксувати етапи перевезення, включаючи час виїзду та доставки. Завдяки IoT-сенсорам у холодильниках, система контролює умови зберігання компонентів крові під час транспортування, забезпечуючи дотримання температурного режиму. У разі виявлення відхилень система автоматично надсилає сповіщення відповідальним особам, що дозволяє оперативно вживати заходів для збереження якості матеріалу.
Мобільний додаток для донорів відіграє не менш важливу роль у підтриманні постійного циклу донацій. Він дозволяє користувачам переглядати історію власних донорських сесій, отримувати індивідуальні рекомендації та підтримку, що сприяє збереженню їхньої мотивації та залученості у процес. Реєстрацію нового донора здійснюють працівники медичних установ, після чого користувач отримує персоніфікований доступ до системи, який він може надалі використовувати для взаємодії з платформою.
Ключовим компонентом є серверна частина, яка забезпечує злагоджену роботу всіх модулів, обробку запитів, авторизацію користувачів, ведення обліку компонентів крові, а також формування статистичних та аналітичних звітів. Саме тут реалізовано логіку розрахунку кількості компонентів крові після обробки, документування кожної транзакції та підтримку актуальної інформації у базі даних. Усі дії в системі фіксуються, що забезпечує прозорість, можливість аудиту та прийняття обґрунтованих управлінських рішень.
Загалом програмна система створює інтегровану інфраструктуру, яка сприяє підвищенню ефективності у сфері донорства крові. Вона покликана мінімізувати людський фактор у критичних процесах, зменшити ризики втрат чи помилок, а також сформувати сучасний рівень взаємодії між усіма залученими сторонами. У результаті користувачі платформи — як медичні працівники, так і донори — отримують інструменти, що забезпечують зручність, оперативність, безпеку й повну цифрову підтримку усіх етапів процесу, спрямованого на збереження людських життів.





3.2	   Загальний огляд використаних технологій


На діаграмі представлено архітектуру програмної системи для управління банком крові, яка включає мобільний застосунок, серверну частину, веб-клієнт, базу даних, підсистему резервного копіювання та IoT-емулятор холодильників із кров’ю. Центральним елементом виступає сервер додатка, побудований на основі фреймворка Flask, який забезпечує легкість та гнучкість при створенні RESTful API. Flask дозволяє швидко додавати необхідні функціональні модулі — зокрема, бізнес-логіку, обробку аутентифікації (через JWT-модуль), та роботу з ORM-рівнем SQLAlchemy, що значно спрощує доступ до бази даних без написання сирих SQL-запитів.
У якості системи керування базами даних використовується Microsoft SQL Server, яка забезпечує стабільність, масштабованість і хорошу інтеграцію з інструментами резервного копіювання. Зв’язок між сервером і СУБД реалізується через ODBC, що забезпечує надійну взаємодію між Python-орієнтованим бекендом і СУБД корпоративного класу. Резервне копіювання даних реалізовано через окремий шар, що зберігає бекапи у локальній файловій системі, що гарантує збереження критичних даних у разі збоїв.
Для обробки даних з IoT-сенсорів (датчиків температури в холодильниках) передбачено емулятор сенсорів, реалізований за допомогою Python та бібліотеки Tkinter. Це рішення дозволяє моделювати поведінку пристроїв у тестовому середовищі без потреби у фізичному обладнанні. Дані передаються до серверної частини через HTTP, що відповідає сучасним стандартам обміну даними між пристроями в IoT-середовищі.
Веб-клієнт, побудований на Django, забезпечує функціональність для медичного персоналу та адміністраторів. Django обрано через його надійність, потужну реалізацію шаблонів, сесій, форм і безпеки, що дозволяє створити масштабовану адміністративну панель з усім необхідним функціоналом. Django добре інтегрується з Python-екосистемою, що спрощує взаємодію з сервером додатка.
Ключовим компонентом системи є мобільний застосунок, реалізований на Kotlin для платформи Android. Kotlin обрано через його нативну інтеграцію з Android SDK, лаконічний синтаксис, безпечну роботу з пам’яттю та сучасні інструменти розробки. Мобільний клієнт використовує архітектурну модель MVC: графічний інтерфейс (View) створено через XML Layouts, логіка користувача обробляється в Activities/Fragments (Controller), а взаємодія з сервером — у модулі Model через Retrofit + OkHttp. Адаптери для RecyclerView та модулі ресурсів реалізують підтримку списків, повідомлень і локалізованих налаштувань, що важливо для кінцевих користувачів, зокрема донорів і транспортувальників.
Вибір саме таких технологій зумовлений кількома факторами. По-перше, всі компоненти побудовані на відкритих стандартах та мові Python, що забезпечує легкість у розробці, хорошу підтримку спільноти та широкі можливості масштабування. Flask і Django доповнюють один одного: перший забезпечує легкий та керований бекенд, другий — повнофункціональний веб-інтерфейс. Kotlin як основна мова для Android дозволяє створити нативний, швидкий і сучасний мобільний застосунок. Обрана комбінація технологій є сумісною, добре документованою та широко підтримуваною, що дозволяє ефективно розробляти та розгортати систему в умовах обмежених ресурсів і водночас гарантує надійність, безпеку та зручність для кінцевих користувачів.

Рисунок 3.1 – UML Діаграма компонентів


3.3	    Локальне розгортання програмної системи


	Локальне розгортання програмної системи для управління банками крові передбачає налаштування всіх основних її компонентів: серверної частини (бекенду), IoT-емулятора, бази даних, вебінтерфейсу (фронтенду) та мобільного застосунку. Для забезпечення коректної роботи всієї інфраструктури на одному комп’ютері необхідно заздалегідь підготувати середовище, встановити всі необхідні інструменти, а також провести початкове налаштування конфігурацій.
Вимоги до системи та необхідне програмне забезпечення:
	Операційна система: Windows 10/11 або Linux/macOS
	Оперативна пам’ять: мінімум 8 ГБ
	Процесор: від 4 ядер, 2.0 GHz і вище
	Вільне місце на диску: щонайменше 5–10 ГБ
	Python 3.10 або вище
	pip (менеджер пакетів Python)
	Git
	Microsoft SQL Server та SSMS (SQL Server Management Studio)
	Android Studio + JDK 11+
	Сучасний браузер (Chrome або Firefox)
На початку слід завантажити архів із програмним кодом проєкту та розпакувати його у відповідну директорію. Після цього необхідно відкрити термінал або командний рядок, перейти до кореневої директорії проєкту за допомогою команди cd.
	Для ізоляції залежностей рекомендується створити віртуальне середовище за допомогою команди python -m venv venv. Ця команда створює директорію venv, що містить локальну копію Python і необхідні бібліотеки. Віртуальне середовище активується на Windows командою venv\Scripts\activate, на macOS/Linux командою source venv/bin/activate. 
	Після активації середовища необхідно встановити всі залежності, вказані у файлі requirements.txt командою pip install -r requirements.txt. 
	Для роботи системи створюється файл .env у кореневій директорії проєкту, який має містити такі параметри:


1   SECRET_KEY="згенероване_значення"
2   DATABASE_URL="посилання_на_базу"
3   JWT_SECRET_KEY="згенероване_значення"
4   DATABASE_NAME = "ім’я_бази"
5   BACKUP_DIR = "шлях_до_папки_де_зберігатимуться_бекапи"
6   FLASK_APP="run.py"

Секретні ключі SECRET_KEY і JWT_SECRET_KEY можна згенерувати у Python-консолі за допомогою команди python -c "import secrets; print(secrets.token_hex(32))". Параметр DATABASE_URL налаштовується відповідно до конфігурації сервера Microsoft SQL Server.
Параметр BACKUP_DIR потрібний для налаштування резервного копіювання бази даних. Вказується шлях до папки з бекапами, назва файлу бекапу буде складатися з імені бази, слова бекап та часової мітки.
Для запуску серверу Flask виконується команда flask run Після запуску сервер стає доступним за адресою http://127.0.0.1:5000. 
IoT-емулятор, що імітує роботу холодильників із кров’ю, розгортається аналогічним чином: його код розпаковується у окрему папку, після чого в тій самій директорії створюється віртуальне середовище. Після активації середовища встановлюються залежності, зазначені у відповідному requirements.txt. Сам емулятор запускається через головний файл проєкту — після чого він починає надсилати HTTP-запити на бекенд із симульованими показниками температури.
Розгортання скрипта бази даних у Microsoft SQL Server передбачає виконання декількох етапів. Перш за все, відкривається Microsoft SQL Server Management Studio (SSMS) та підключається до потрібного інстансу сервера, вказуючи дані для аутентифікації.
Далі завантажується скрипт бази даних. Це виконується через меню File, де потрібно обрати Open → File і вказує шлях до скрипта. У скрипті потрібно змінити FILENAME рис 3.2. 

Рисунок 3.2 –Налаштування FILENAME у скрипті бази даних Blood bank

 Для запуску скрипта натискається кнопка Execute або використовується клавіша F5. Після завершення виконання потрібно перевірити успішність операції, переглядаючи повідомлення в нижньому вікні. Потім здійснюється візуальна перевірка створених таблиць через панель Object Explorer. 
	Для забезпечення надійності та ефективності роботи зі скриптами бази даних потрібно дотримуватися таких правил, а саме перед виконанням будь-якого скрипта, який вносить зміни у вже існуючу базу даних, необхідно створити резервну копію, це дозволить уникнути втрати даних у разі помилок під час виконання. Слід перевірити, що версія SQL Server відповідає тій, для якої створено скрипт. Невідповідність може призвести до помилок або некоректної роботи бази даних.
	Фронтенд-сервер створено з використанням фреймворку Django. Його розгортання починається з переходу до директорії з фронтендом, створення віртуального середовища та встановлення залежностей. Далі необхідно виконати міграції бази даних, які створюють таблиці для внутрішньої логіки Django, зокрема для авторизації та адміністративної панелі. Після цього вебсервер запускається, і його інтерфейс стає доступним у браузері за адресою http://127.0.0.1:8000. Ця частина системи орієнтована переважно на адміністраторів і медичний персонал, надаючи доступ до візуального інтерфейсу, форм, таблиць та інших функцій.

	Мобільний застосунок розроблений на мові Kotlin з використанням Android Studio. Для його запуску необхідно відкрити проєкт у середовищі Android Studio, дочекатися повного завантаження та збирання проєкту через Gradle, а також переконатися у наявності емулятора або фізичного Android-пристрою. У файлах застосунку (зокрема ApiClient) важливо вказати правильну адресу локального бекенду. У випадку використання Android-емулятора стандартною адресою є http://10.0.2.2:5000, яка відповідає localhost з перспективи віртуального пристрою. Після цього застосунок можна запустити, що дозволить симулювати роботу користувача (донора або транспортувальника), відображати повідомлення та координувати процеси доставки крові.


3.4	    Хмарне розгортання та деплой


	Для забезпечення масштабованості, високої доступності та централізованого управління розгортанням програмної системи для управління банком крові доцільно використати хмарну інфраструктуру. Одним із найбільш оптимальних рішень є використання платформи Microsoft Azure, яка забезпечує широкий спектр сервісів для розміщення бекенд-сервісів, баз даних, веб-клієнтів, мобільної взаємодії та емуляції IoT-компонентів. Хмарне середовище дозволяє автоматизувати процеси деплою, тестування, масштабування та резервного копіювання, що підвищує надійність та ефективність обслуговування програмної системи.
	Серверна частина системи реалізована з використанням Flask, що дозволяє її контейнеризувати за допомогою Docker. Образ системи створюється локально або в рамках CI/CD-процесу і публікується до Azure Container Registry (ACR). Після цього він автоматично деплоїться на Azure App Service – керований сервіс платформи як сервіс (PaaS), який дозволяє запускати веб-додатки у Docker-контейнерах без необхідності самостійно налаштовувати інфраструктуру.
	Для автоматизації розгортання використовується CI/CD-пайплайн, побудований на основі GitHub Actions. При кожному пуші до гілки main або release, GitHub Actions виконує такі кроки: створення Docker-образу серверної частини, його авторизація в ACR, завантаження в реєстр і тригер автоматичного оновлення Azure Web App. Усі змінні оточення, такі як секретні ключі, URL бази даних, ключі JWT, зберігаються в захищених секретах GitHub та передаються як змінні середовища до контейнера.
	База даних Microsoft SQL Server також може бути розгорнута у хмарі за допомогою Azure SQL Database, що забезпечує автоматичне резервне копіювання, масштабування за потребою, шифрування та захист від збоїв. Доступ до бази налаштовується через віртуальну мережу та обмежується для додаткової безпеки.
	Веб-клієнт, реалізований з використанням Django, може бути розгорнутий окремо як самостійна веб-служба або як частина мультиконтейнерного Docker-додатку в Azure App Service або Azure Kubernetes Service (AKS) для масштабованого управління контейнерами. Мобільний застосунок, з огляду на його нативну реалізацію, розгортається через Google Play, однак взаємодіє з бекендом за допомогою HTTP-запитів до API, розміщеного в хмарі.
	IoT-емулятор сенсорів можна запустити як окремий контейнер або локальний додаток, що надсилає дані до API у хмарі. За потреби реальні сенсори можуть використовувати MQTT або HTTP-з’єднання до публічної IP-адреси бекенду.
	Така архітектура дозволяє масштабувати окремі компоненти незалежно одна від одної, оновлювати окремі сервіси без зупинки всієї системи, а також забезпечити fault tolerance через використання зон високої доступності в Azure.
Таким чином, хмарне розгортання системи з використанням CI/CD, контейнеризації, Azure Web App і керованих служб баз даних значно підвищує надійність та зменшує витрати на підтримку. Це забезпечує готовність системи до реального використання, розширення та інтеграції з зовнішніми службами.

 
Рисунок 3.3 – Архітектурна діаграма хмарного розгортання програмної системи на платформі Microsoft Azure

Діаграма ілюструє хмарну архітектуру розгортання програмної системи управління банком крові з використанням платформи Microsoft Azure. У центрі архітектури розміщено Flask API, який є основним логічним ядром системи. Саме через нього взаємодіють усі інші компоненти – вебклієнт, мобільний застосунок, емулятор IoT-пристрою та база даних.
Система CI/CD побудована на основі GitHub Actions, яка автоматизує процес оновлення та розгортання додатків. Після кожного оновлення коду GitHub Actions або безпосередньо передає зміни у сервіс Azure Web App, або зберігає контейнеризовану версію застосунку в Azure Container Registry. Далі Azure Web App завантажує відповідний контейнер з реєстру та забезпечує доступність сервісу в мережі. У цьому середовищі хоститься як бекенд на Flask, так і вебінтерфейс, реалізований за допомогою Django.
Користувачі можуть взаємодіяти з системою через вебінтерфейс або мобільний застосунок. Обидва клієнти надсилають запити до Flask API, який, у свою чергу, звертається до хмарної бази даних Azure SQL Database. Емулятор пристрою IoT, який моделює роботу “розумного” холодильника, також надсилає дані безпосередньо до Flask API, забезпечуючи моніторинг умов зберігання крові.
Завдяки використанню Azure дана архітектура є гнучкою та масштабованою: кожен компонент можна розгортати, оновлювати або масштабувати незалежно, а хмарна інфраструктура гарантує високу доступність, безпеку та надійність системи.


3.5	    Висновки


У ході виконання лабораторної роботи було проведено повний аналіз архітектури програмної системи для управління банками крові та координації донорських процесів. Розглянуто її функціональну структуру, ключові компоненти та взаємодію між ними. Проведено порівняльний огляд використаних технологій, що дозволило обґрунтувати вибір програмного стеку з урахуванням вимог до продуктивності, масштабованості та зручності підтримки.
Було виконано як локальне, так і хмарне розгортання системи. При локальному розгортанні вдалося забезпечити працездатність усіх компонентів у тестовому середовищі, що дало змогу перевірити функціональність системи. Хмарне розгортання на платформі Microsoft Azure дозволило забезпечити доступність сервісу, покращити надійність та підготувати систему до масштабування.
Отримані результати підтвердили ефективність обраного підходу до побудови програмної архітектури. Використання сучасних технологій та хмарних рішень дозволяє створити гнучку, адаптивну та стійку до навантажень систему, яка може успішно застосовуватись у медичних установах для оптимізації процесів, пов’язаних із донорством крові.



ДОДАТОК А
Хронологічний опис відео

Відеозапис доповіді на YouTube: https://youtu.be/MoXEjiT-UOk
Хронологічний опис відео 
00:00 Вступ 
00:10 Розділ 2 Завдання до лабораторної роботи 
00:54 Розділ 3.1 Загальний огляд програмної системи 
03:29 Розділ 3.2 Загальний огляд використаних технологій 
06:24 Розділ 3.3 Локальне розгортання програмної системи 
09:36 Розділ 3.4 Хмарне розгортання та деплой 
12:15 Висновки

Посилання на файл з кодом в GitHub репозиторії: https://github.com/NureRubanenkoMariia/apz-pzpi-22-7-rubanenko-mariia/tree/main/Lab5/apz-pzpi-22-7-rubanenko-mariia-lab5





ДОДОТОК Б


 1  name: Deploy to Azure
 2  
 3  on:
 4    push:
 5      branches:
 6        - main
 7  
 8  jobs:
 9    build-and-deploy:
10      runs-on: ubuntu-latest
11  
12      env:
13        AZURE_WEBAPP_NAME: blood-bank-backend
14        AZURE_RESOURCE_GROUP: blood-bank-rg
15        AZURE_CONTAINER_REGISTRY: bloodbankregistry.azurecr.io
16        IMAGE_NAME: bloodbank-backend
17  
18      steps:
19        - name: Checkout repository
20          uses: actions/checkout@v3
21  
22        - name: Set up Python
23          uses: actions/setup-python@v4
24          with:
25            python-version: '3.10'
26  
27        - name: Log in to Azure CLI
28          uses: azure/login@v1
29          with:
30            creds: ${{ secrets.AZURE_CREDENTIALS }}
31  
32        - name: Log in to Azure Container Registry
33          run: |
34            az acr login --name ${{ env.AZURE_CONTAINER_REGISTRY }}
35  
36        - name: Build and push Docker image
37          run: |
38            docker build -t ${{ env.AZURE_CONTAINER_REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }} .
39            docker push ${{ env.AZURE_CONTAINER_REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}
40  
41        - name: Deploy to Azure Web App
42          run: |
43            az webapp config container set \
44              --name ${{ env.AZURE_WEBAPP_NAME }} \
45              --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \
46              --docker-custom-image-name ${{ env.AZURE_CONTAINER_REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }} \
47              --docker-registry-server-url https://${{ env.AZURE_CONTAINER_REGISTRY }}
48            az webapp restart --name ${{ env.AZURE_WEBAPP_NAME }} --resource-group ${{ env.AZURE_RESOURCE_GROUP }}
